# Azure Foundry Multi-Agent System

Complete implementation of a multiagent system using **Azure AI Foundry Service** with **Azure Multi-Agent Orchestration**. All 6 agents (Supervisor, Planner, Executor, SQL, RAG, Response Generator) are hosted in Azure Foundry and leverage Azure's built-in orchestration capabilities.

## Architecture Overview

```
┌─────────────────────────────────────────────────────────────┐
│              Azure AI Foundry Project                        │
│  ┌────────────────────────────────────────────────────────┐ │
│  │        Azure Multi-Agent Orchestration                 │ │
│  │                                                        │ │
│  │  [Supervisor] → [Planner] → [Executor]                │ │
│  │                      ↓           ↓                     │ │
│  │              [SQL Agent]   [RAG Agent]                │ │
│  │                      ↓                                 │ │
│  │              [Response Generator]                      │ │
│  └────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│  Data Sources: Azure SQL, Azure AI Search, Local Databases  │
└─────────────────────────────────────────────────────────────┘
```

## Features

✅ **Full Azure Deployment** - All agents hosted in Azure Foundry
✅ **Azure Multi-Agent Orchestration** - Built-in agent-to-agent handoffs
✅ **Mixed Data Sources** - Azure + local databases with secure connectivity
✅ **Managed Infrastructure** - Auto-scaling, monitoring, and updates
✅ **Advanced Models** - GPT-4o with model router
✅ **Event Streaming** - Real-time workflow progress
✅ **Approval Gates** - Security controls for risky operations

## Quick Start

### Prerequisites

1. **Azure Subscription** with permissions to create resources
2. **Azure CLI** installed and configured (`az login`)
3. **Python 3.10+** with pip
4. **ODBC Driver 18 for SQL Server** (for Azure SQL)

### Installation

```bash
# Clone the repository
cd agent-framework

# Install Python dependencies
source venv/bin/activate
pip install -e python/packages/core
pip install azure-ai-projects azure-identity azure-keyvault-secrets pyodbc

# Or install all Azure dependencies
pip install azure-ai-projects azure-ai-agents azure-identity azure-keyvault-secrets pyodbc
```

### Step 1: Deploy Azure Infrastructure

```bash
# Deploy all Azure resources (takes 10-15 minutes)
./scripts/deploy_infrastructure.sh

# This creates:
# - AI Foundry Hub & Project
# - Azure SQL Database
# - Azure AI Search
# - Key Vault
# - Application Insights
# - Storage Account
```

The deployment script will generate a `.env.azure` file with all your endpoints and connection strings.

### Step 2: Create Agents in Azure Foundry

```bash
# Load environment variables
export $(cat .env.azure | xargs)

# Create all 6 agents
python scripts/create_azure_agents.py

# This creates:
# - Supervisor Agent (GPT-4o, temp=0.5)
# - Planner Agent (GPT-4o, temp=0.7, JSON output)
# - Executor Agent (GPT-4o, temp=0.5)
# - SQL Agent (GPT-4o, temp=0.3)
# - RAG Agent (GPT-4o, temp=0.5, File Search)
# - Response Generator (GPT-4o, temp=0.7)

# Configuration saved to: azure_agents_config.json
```

### Step 3: Run Examples

#### End-to-End Workflow

```bash
python examples/azure_foundry_workflow_example.py
```

This example demonstrates:
- Mixed data source access (Azure SQL + local SQLite)
- Tool execution with approval gates
- Complete supervisor orchestration
- Formatted table output

#### Simple SQL Query

```bash
python examples/azure_simple_sql_example.py
```

Quick example of SQL agent query execution.

#### Streaming Workflow

```bash
python examples/azure_streaming_example.py
```

Real-time streaming responses from agents.

## Configuration

### Environment Variables

The `.env.azure` file (generated by deployment script) contains:

```bash
# Azure AI Foundry
AZURE_AI_PROJECT_ENDPOINT=https://your-project.api.azureml.ms
AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o

# Azure SQL
AZURE_SQL_SERVER=your-server.database.windows.net
AZURE_SQL_DATABASE=your-database

# Azure AI Search
AZURE_SEARCH_ENDPOINT=https://your-search.search.windows.net
AZURE_SEARCH_INDEX_NAME=schema-docs

# Key Vault
AZURE_KEYVAULT_URI=https://your-keyvault.vault.azure.net/

# Application Insights
APPINSIGHTS_CONNECTION_STRING=InstrumentationKey=...
```

### Agent Configuration

The `azure_agents_config.json` file (generated by agent creation script) contains:

```json
{
  "created_at": "...",
  "project_endpoint": "...",
  "model": "gpt-4o",
  "agents": {
    "supervisor": {"id": "agent-xyz", "name": "supervisor_agent"},
    "planner": {"id": "agent-abc", "name": "planner_agent"},
    ...
  }
}
```

## Usage Guide

### Creating an Agent Adapter

```python
from azure.ai.projects.aio import AIProjectClient
from azure.identity.aio import DefaultAzureCredential
from agent_framework_azure_ai import AzureFoundryAgentAdapter, ToolExecutor

# Initialize Azure client
credential = DefaultAzureCredential()
project_client = AIProjectClient(
    credential=credential,
    endpoint=os.environ["AZURE_AI_PROJECT_ENDPOINT"]
)

# Load agent configuration
with open("azure_agents_config.json") as f:
    config = json.load(f)

# Create adapter
supervisor = AzureFoundryAgentAdapter(
    agents_client=project_client.agents,
    agent_id=config["agents"]["supervisor"]["id"],
    agent_name="supervisor_agent",
    tool_executor=tool_executor
)

# Use like any local agent
response = await supervisor.run("Analyze Q4 sales by region")
print(response.messages[0].text)
```

### Registering Tools

```python
from agent_framework_azure_ai import ToolExecutor

tool_executor = ToolExecutor()

# Register synchronous tool
def get_schema(database: str) -> str:
    return connector.get_schema()

tool_executor.register("get_database_schema", get_schema)

# Register asynchronous tool
async def execute_query(query: str, database: str):
    results = await connector.run_query_async(query)
    return results

tool_executor.register("execute_sql_query", execute_query)
```

### Mixed Data Sources

```python
from agent_framework_azure_ai import AzureSQLConnector
from agent_framework.data.connectors import SQLiteConnector
from agent_framework.orchestrator.context import OrchestrationContext

# Azure SQL with Managed Identity
azure_sql = AzureSQLConnector(
    server="myserver.database.windows.net",
    database="sales-db",
    use_managed_identity=True
)

# Local SQLite
local_sqlite = SQLiteConnector(db_path="products.db")

# Register both in context
context = OrchestrationContext()
context = context.with_connector("azure_sales", azure_sql)
context = context.with_connector("local_products", local_sqlite)

# Agents can query both seamlessly
```

## Architecture Details

### Agent Responsibilities

| Agent | Model | Temp | Purpose |
|-------|-------|------|---------|
| **Supervisor** | GPT-4o | 0.5 | Master orchestrator, analyzes requests, coordinates agents |
| **Planner** | GPT-4o | 0.7 | Creates workflow plans with dependencies (JSON output) |
| **Executor** | GPT-4o | 0.5 | Step-by-step execution with user feedback |
| **SQL Agent** | GPT-4o | 0.3 | SQL generation with retry logic (3 attempts) |
| **RAG Agent** | GPT-4o | 0.5 | Document search with File Search tool (top_k=20) |
| **Response Generator** | GPT-4o | 0.7 | Formats final responses with citations |

### Multi-Agent Communication

Azure Foundry's multi-agent orchestration uses **function tool invocations** for agent handoffs:

```python
# Supervisor invokes Planner
supervisor → invoke_agent(agent_name="planner_agent", message=user_request)

# Planner creates plan and returns to Supervisor
planner → returns WorkflowPlan (JSON)

# Supervisor invokes Executor with plan
supervisor → invoke_agent(agent_name="executor_agent", message=plan)

# Executor invokes SQL/RAG agents as needed
executor → invoke_agent(agent_name="sql_agent", message=query)
```

All agents share the same **thread ID** for conversation continuity.

### Data Flow

```
User Request
    ↓
Supervisor (analyzes & routes)
    ↓
Planner (creates workflow plan)
    ↓
Executor (executes step-by-step)
    ↓
SQL/RAG Agents (retrieve data)
    ↓
Response Generator (formats output)
    ↓
User
```

## Local Database Access

For accessing local databases from Azure agents, use one of these options:

### Option 1: Azure Dev Tunnels (Development)

```bash
# Install dev tunnels
curl -sL https://aka.ms/DevTunnelsCli-Install | bash

# Create tunnel for local PostgreSQL
devtunnel create
devtunnel port create -p 5432
devtunnel host

# Use tunnel URL in agent configuration
export DEV_TUNNEL_URL=https://abc123.devtunnels.ms
```

### Option 2: Azure Relay Hybrid Connections (Production)

See Azure documentation for setting up Hybrid Connections to on-premises databases.

### Option 3: VPN Gateway (Enterprise)

Site-to-site VPN between Azure VNet and on-premises network.

## Monitoring & Observability

### Application Insights

All agent operations are logged to Application Insights automatically.

**View logs in Azure Portal:**
1. Navigate to Application Insights resource
2. Go to Logs
3. Query traces:

```kusto
traces
| where cloud_RoleName == "multiagent-system"
| where severityLevel >= 2
| project timestamp, message, customDimensions
| order by timestamp desc
```

### Metrics

Monitor key metrics:
- Agent response time
- Tool execution success rate
- Error rate by agent type
- Token usage per request

## Troubleshooting

### Common Issues

#### 1. "ModuleNotFoundError: No module named 'azure.ai.agents'"

```bash
pip install azure-ai-agents azure-ai-projects
```

#### 2. "Authentication failed"

```bash
# Login to Azure
az login

# Set subscription
az account set --subscription "your-subscription-id"

# Verify
az account show
```

#### 3. "Agent run failed: Model deployment not found"

Ensure GPT-4o is deployed in your Azure AI Foundry project:
1. Go to Azure AI Foundry portal
2. Navigate to Deployments
3. Deploy gpt-4o model
4. Update `AZURE_AI_MODEL_DEPLOYMENT_NAME` in `.env.azure`

#### 4. "Connection to Azure SQL failed"

Check:
- Managed Identity is enabled on Azure resource
- SQL Server firewall allows Azure services
- Database credentials are correct

```bash
# Test SQL connection
sqlcmd -S your-server.database.windows.net -d your-database -G -C
```

## Development Workflow

### Making Changes to Agents

To update agent instructions or tools:

1. **Modify agent creation script:**
   ```python
   # scripts/create_azure_agents.py
   def get_supervisor_instructions():
       return "Updated instructions..."
   ```

2. **Recreate agents:**
   ```bash
   python scripts/create_azure_agents.py
   ```

3. **Test changes:**
   ```bash
   python examples/azure_foundry_workflow_example.py
   ```

### Adding New Tools

1. **Define tool in agent creation script:**
   ```python
   {
       "type": "function",
       "function": {
           "name": "new_tool",
           "description": "Description",
           "parameters": {...}
       }
   }
   ```

2. **Register handler in ToolExecutor:**
   ```python
   def new_tool_handler(param1: str) -> str:
       # Implementation
       return result

   tool_executor.register("new_tool", new_tool_handler)
   ```

3. **Test tool execution**

## Cost Optimization

### Estimated Costs (per 1000 requests)

| Component | Cost |
|-----------|------|
| GPT-4o API calls | $15-30 |
| Azure AI Search (Standard) | $0.25/hour |
| Azure SQL (S0) | $15/month |
| Key Vault | $0.03/10k ops |
| Application Insights | $2.30/GB |

**Tips:**
- Use lower temperature for SQL agent (0.3) to reduce tokens
- Implement caching for repeated queries
- Use streaming for better UX without cost increase
- Monitor token usage in Application Insights

## Security Best Practices

✅ **Use Managed Identity** for Azure resource access
✅ **Store secrets in Key Vault**, not in code
✅ **Enable approval gates** for SQL writes (INSERT, UPDATE, DELETE)
✅ **Limit SQL row returns** to 500 maximum
✅ **Validate all user inputs** before passing to agents
✅ **Enable audit logging** in Application Insights
✅ **Use private endpoints** for production deployments

## Next Steps

1. **Upload Schema Documentation** for RAG agent:
   ```python
   # Upload documents
   file = await agents_client.upload_file("schema_docs.pdf", purpose="assistants")

   # Create vector store
   vector_store = await agents_client.create_vector_store(
       name="schema_docs",
       file_ids=[file.id]
   )

   # Update RAG agent
   await agents_client.update_agent(
       agent_id=rag_agent_id,
       tool_resources={"file_search": {"vector_store_ids": [vector_store.id]}}
   )
   ```

2. **Configure Azure AI Search** for enterprise document search

3. **Set up CI/CD pipeline** for automated deployments

4. **Implement monitoring dashboards** in Azure Portal

5. **Add custom agents** for domain-specific tasks

## Support

- **Azure AI Foundry Documentation**: https://learn.microsoft.com/en-us/azure/ai-foundry/
- **Agent Framework Issues**: https://github.com/anthropics/claude-code/issues
- **Azure Support**: https://azure.microsoft.com/support/

## License

Copyright (c) Microsoft. All rights reserved.
